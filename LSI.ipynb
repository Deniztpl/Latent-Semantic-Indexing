{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dbf403",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321867fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cleaning data\n",
    "df = pd.read_csv(\"comcast_consumeraffairs_complaints.csv\")\n",
    "df.dropna(subset=[\"text\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1f2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dates(date_string):\n",
    "    year = int(date_string[-2:])\n",
    "    return year >= 9\n",
    "\n",
    "df = df[df['posted_on'].apply(filter_dates)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd62a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = \"NLTK's list of english stopwords\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "stopwords = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a50738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 5058)\n"
     ]
    }
   ],
   "source": [
    "# Matrix initialization part\n",
    "\n",
    "# Tokenization\n",
    "df['tokens'] = df['text'].apply(word_tokenize)\n",
    "\n",
    "# Stopword removal\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.lower() not in stopwords])\n",
    "\n",
    "# Remove tokens containing any digit\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if not re.search(r'\\d', word)])\n",
    "\n",
    "# Remove any term containing punctuations\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "df['clean_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Vectorize tokenized and cleaned text\n",
    "vectorizer = CountVectorizer()\n",
    "term_doc_matrix = vectorizer.fit_transform(df['clean_text'])\n",
    "term_doc_df = pd.DataFrame(term_doc_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "A_hat = term_doc_df.values.T\n",
    "A = A_hat / np.linalg.norm(A_hat, axis=0) # Normalize\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11294038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abhorr</th>\n",
       "      <th>abid</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>...</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipcod</th>\n",
       "      <th>zogbi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5054</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5058 rows × 8732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron  aback  abandon  abc  abhor  abhorr  abid  abil  abl  abnorm  ...  \\\n",
       "0         0      0        0    0      0       0     0     0    0       0  ...   \n",
       "1         0      0        0    0      0       0     0     0    0       0  ...   \n",
       "2         0      0        0    0      0       0     0     0    0       0  ...   \n",
       "3         0      0        0    0      0       0     0     0    0       0  ...   \n",
       "4         0      0        0    0      0       0     0     0    0       0  ...   \n",
       "...     ...    ...      ...  ...    ...     ...   ...   ...  ...     ...  ...   \n",
       "5053      0      0        0    0      0       0     0     0    0       0  ...   \n",
       "5054      0      0        0    0      0       0     0     0    0       0  ...   \n",
       "5055      0      0        0    0      0       0     0     0    0       0  ...   \n",
       "5056      0      0        0    0      0       0     0     0    0       0  ...   \n",
       "5057      0      0        0    0      0       0     0     0    0       0  ...   \n",
       "\n",
       "      zenith  zero  zillion  zion  zip  zipcod  zogbi  zombi  zone  zoom  \n",
       "0          0     0        0     0    0       0      0      0     0     0  \n",
       "1          0     0        0     0    0       0      0      0     0     0  \n",
       "2          0     0        0     0    0       0      0      0     0     0  \n",
       "3          0     0        0     0    0       0      0      0     0     0  \n",
       "4          0     0        0     0    0       0      0      0     0     0  \n",
       "...      ...   ...      ...   ...  ...     ...    ...    ...   ...   ...  \n",
       "5053       0     0        0     0    0       0      0      0     0     0  \n",
       "5054       0     0        0     0    0       0      0      0     0     0  \n",
       "5055       0     0        0     0    0       0      0      0     0     0  \n",
       "5056       0     0        0     0    0       0      0      0     0     0  \n",
       "5057       0     0        0     0    0       0      0      0     0     0  \n",
       "\n",
       "[5058 rows x 8732 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b2bf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular values:\n",
      "(505, 505)\n",
      "Left singular vectors (U matrix):\n",
      "(8732, 505)\n",
      "Right singular vectors (V^T matrix):\n",
      "(505, 5058)\n",
      "Elapsed time: 251.12 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVD IMPLEMENTATION\n",
    "# Note: Since 5200x9000 Matrix is too much to compute, I have decided to not\n",
    "# compute whole matrix. Instead compute with approximation directly with k = min(t,d) / 10\n",
    "# Took 527 second maximum on my computer.\n",
    "\n",
    "import time\n",
    "\n",
    "def power_iteration(B, num_simulations):\n",
    "    b_k = np.random.normal(0, 1, B.shape[1])\n",
    "    for _ in range(num_simulations):\n",
    "        # Iterate with given iteration until vector and value converges\n",
    "        b_k1 = np.dot(B, b_k)\n",
    "        eigenvalue = np.linalg.norm(b_k1)\n",
    "        b_k = b_k1 / eigenvalue\n",
    "\n",
    "    return b_k, eigenvalue\n",
    "\n",
    "def svd_from_scratch(A, num_values, num_iterations):\n",
    "    ATA = np.dot(A.T, A)\n",
    "    vectors = []\n",
    "    values = []\n",
    "\n",
    "    for _ in range(num_values):\n",
    "        eigenvector, eigenvalue = power_iteration(ATA, num_iterations)\n",
    "        values.append(eigenvalue)\n",
    "        vectors.append(eigenvector)\n",
    "        \n",
    "        # Subtract to find next eigenvalues and vectors given with number of num_values\n",
    "        ATA -= eigenvalue * np.outer(eigenvector, eigenvector)\n",
    "\n",
    "    # Compute the singular values\n",
    "    singular_values = np.sqrt(values)\n",
    "    V = np.array(vectors).T\n",
    "\n",
    "    # Compute U\n",
    "    U = np.dot(A, V) / singular_values\n",
    "\n",
    "    return U, singular_values, V.T\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "# k value = min(t,d) / 10\n",
    "k = min(A.shape) // 10\n",
    "\n",
    "# Build U_k, s_k, Vt_k with k = 510\n",
    "# eg. U_k = first k column of U\n",
    "\n",
    "U, s, Vt = svd_from_scratch(A, num_values=k, num_iterations=50)\n",
    "S = np.diag(s)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time \n",
    "\n",
    "print(\"Singular values:\")\n",
    "print(S.shape)\n",
    "print(\"Left singular vectors (U matrix):\")\n",
    "print(U.shape)\n",
    "print(\"Right singular vectors (V^T matrix):\")\n",
    "print(Vt.shape)\n",
    "\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44caaa",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f106e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k value = 490 , MSE = 1.4292843825709602e-05\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "# k = 10, 30,... , min(t,d) / 10\n",
    "step_size = 20\n",
    "my_list = [i for i in range(10, k + 1, step_size)]\n",
    "\n",
    "least_error = float('inf')   # Error variable initialized\n",
    "k_value = 0    # k variable initialized\n",
    "for k in my_list:\n",
    "    # Constructing A_hat: 8874x5190 approximated matrix\n",
    "    U_k = U[:, :k]\n",
    "    S_k = S[:k, :k]\n",
    "    Vt_k = Vt[:k, :]\n",
    "    A_hat = np.dot(np.dot(U_k, S_k), Vt_k) \n",
    "    \n",
    "    # MSE values for each k. Take the minimum error.\n",
    "    squared_differences = (A - A_hat) ** 2\n",
    "    total_squared_difference = np.sum(squared_differences)\n",
    "    total_squared_difference = total_squared_difference / (A.shape[0]*A.shape[1])\n",
    "    if total_squared_difference < least_error:\n",
    "        k_value = k\n",
    "        least_error = total_squared_difference\n",
    "print(f\"k value = {k_value} , MSE = {least_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b39e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k value = 490, Frobenius Norm = 25.12497279487233\n"
     ]
    }
   ],
   "source": [
    "# Calculate Frobenius Norm\n",
    "frobenius_norm = float('inf')\n",
    "k_value = 0\n",
    "for k in my_list:\n",
    "    U_k = U[:, :k]\n",
    "    S_k = S[:k, :k]\n",
    "    Vt_k = Vt[:k, :]\n",
    "    A_hat = np.dot(np.dot(U_k, S_k), Vt_k)\n",
    "    squared_differences = (A - A_hat) ** 2\n",
    "    total_squared_difference = np.sum(squared_differences)\n",
    "    result = np.sqrt(total_squared_difference)  # Calculate the actual Frobenius norm\n",
    "    if result < frobenius_norm:\n",
    "        k_value = k\n",
    "        frobenius_norm = result\n",
    "print(f\"k value = {k_value}, Frobenius Norm = {frobenius_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d3e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct A_hat with optimal k value\n",
    "U_k = U[:, :k_value]\n",
    "S_k = S[:k_value, :k_value]\n",
    "Vt_k = Vt[:k_value, :]\n",
    "A_hat = np.dot(np.dot(U_k, S_k), Vt_k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e7a0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 490)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(S_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db68458a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 490)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d13202",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ccb8f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For query1:\n",
      "Related document id: 931, Similarity = 0.0634\n",
      "\n",
      "For query2:\n",
      "Related document id: 279, Similarity = 0.2470\n",
      "\n",
      "For query3:\n",
      "Related document id: 1047, Similarity = 0.2935\n",
      "\n",
      "For query4:\n",
      "Related document id: 1557, Similarity = 0.3052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Queries\n",
    "query1 = {'ignorant', 'overwhelming'}\n",
    "query2 = {'xfinity', 'frustrate', 'adapter', 'verizon', 'router'}\n",
    "query3 = {'terminate', 'rent', 'promotion', 'joke', 'liar', 'internet', 'horrible'}\n",
    "query4 = {'kindergarten', 'ridiculous', 'internet', 'clerk', 'terrible' }\n",
    "\n",
    "queries = [query1, query2, query3, query4]\n",
    "returned_ids = []\n",
    "\n",
    "for index, query in enumerate(queries):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    # Lemmatize each word in query since it is done for terms too.\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in query]\n",
    "    query = [stemmer.stem(word) for word in lemmatized_words]\n",
    "    column_names = list(term_doc_df.columns)\n",
    "    \n",
    "    # Query vector\n",
    "    q = [1 if col in query else 0 for col in column_names]\n",
    "    q = np.array(q)\n",
    "    max_sim = 0\n",
    "    # Iterate for every document d to find maximum similarity.\n",
    "    for i in range(A_hat.shape[1]):\n",
    "        d = A_hat[:,i].tolist() \n",
    "        d = np.array(d)\n",
    "        q_norm = np.linalg.norm(q)\n",
    "        d_norm = np.linalg.norm(d)\n",
    "        sim = np.dot(q, d) / (q_norm * d_norm)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            max_id = i\n",
    "    returned_ids.append(max_id)\n",
    "    print(f\"For query{index + 1}:\")\n",
    "    print(f\"Related document id: {max_id}, Similarity = {max_sim:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac0a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They ignored first amendment rights and ignored dispute letter for over-charging and making false charges for services not provided. Internet is for $29.99 or $10; cable, for $65.54 or $75.  However, Comcast wants $300 a month for services that were not given or started. This is fraud on the account. \n",
      "\n",
      "Xfinity has taken over my wifi without my consent... I would NEVER subscribe to xfinity because of this... Leave me alone and get off my server!!! \n",
      "\n",
      "Since May, it's the second time I have had to go to their office to get a modem.  I was without phone service since I have my Vonage connected to the Comcast Internet service. I am stuck since I had several problems with service and money issues with Verizon that cost me a lot of money.  So my only choice is Comcast. As far as phone service is concerned, Comcast works very well with my Vonage service.  It's a relief that I don't have to call the Internet service provider and Vonage like I always had to with Verizon. I am annoyed that my plan went from 42 or 47 to $65 or more per month and their best excuse was that I had a promotion.  Well, that's not true.  They had never offered me a promotion and if so, that promotion was from 2008 till now.  So I found that the Internet speed is not what they advertise.I am running virus scan and defragmenting my computer drive, gone through the trouble of buying a 1.5tr external drive, and still have problems.  They gave me a promotion after I complained about the increase of my monthly and the service remains mediocre. I downloaded Norton from their website, it totally messed up my PC that I had no Internet and was on the phone for two to three hours.  I had to do a system restore because of that. My Internet speed is even slower than it was and the cost is way over anyone's budget.  Someone has to do something about these companies and their ripping off customers.  It's just not right.  There are days I have a problem checking my emails. It's faster to just check them from my cell phone. My friend had her laptop connected to my Internet (and no other PC was connected to the Internet) and she gave up because the Internet speed was horribly slow. \n",
      "\n",
      "If you are receiving terrible service from Comcast, and Internet connection that's absolutely miserable please email me at **. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in returned_ids:\n",
    "    print(df.loc[index, \"text\"], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
